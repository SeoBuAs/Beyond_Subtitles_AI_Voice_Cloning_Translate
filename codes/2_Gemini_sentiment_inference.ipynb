{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMHp+lnXIqCohvDR644w6SH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Gemini 분류"],"metadata":{"id":"oliPTiFChr3J"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import google.generativeai as genai\n","import time\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from IPython.display import display, Audio\n","import base64\n","import re\n","\n","GOOGLE_API_KEY = \"\"\n","genai.configure(api_key=GOOGLE_API_KEY)\n","\n","df = pd.read_csv('')\n","\n","audio_dir = '/content/a/'\n","model = genai.GenerativeModel('gemini-1.5-pro')\n","\n","EMOTIONS = ['Happiness', 'Sadness', 'Disgust', 'Fear', 'Surprise', 'Anger', 'Other', 'Neutral']\n","\n","def clean_json_string(json_str):\n","    json_str = re.sub(r'//.*?($|\\n)', '', json_str)\n","    json_str = re.sub(r'/\\*.*?\\*/', '', json_str)\n","\n","    cleaned = \"\"\n","    in_string = False\n","    escape_next = False\n","\n","    for char in json_str:\n","        if escape_next:\n","            escape_next = False\n","            cleaned += char\n","            continue\n","\n","        if char == '\\\\' and in_string:\n","            escape_next = True\n","            cleaned += char\n","            continue\n","\n","        if char == '\"' and not escape_next:\n","            in_string = not in_string\n","            cleaned += char\n","            continue\n","\n","        if in_string or char in '{},:\"0123456789.-[] \\t\\n':\n","            cleaned += char\n","\n","    cleaned = re.sub(r',(\\s*[}\\]])', r'\\1', cleaned)\n","    cleaned = re.sub(r'([{,]\\s*)([a-zA-Z0-9_]+)(\\s*:)', r'\\1\"\\2\"\\3', cleaned)\n","\n","    return cleaned\n","\n","def get_audio_data(audio_path):\n","    with open(audio_path, 'rb') as audio_file:\n","        audio_data = audio_file.read()\n","    return audio_data\n","\n","def analyze_audio_and_text(audio_data, text):\n","    prompt = f\"\"\"\n","    Analyze the emotions expressed in this audio and text.\n","    Text: \"{text}\"\n","\n","    For each of the following emotion categories, indicate if the emotion is present (1) or not present (0):\n","    - Happiness\n","    - Sadness\n","    - Disgust\n","    - Fear\n","    - Surprise\n","    - Anger\n","    - Other\n","    - Neutral\n","\n","    Your response MUST be ONLY a valid JSON object with NO COMMENTS, like this:\n","    {{\n","      \"Happiness\": 0 or 1,\n","      \"Sadness\": 0 or 1,\n","      \"Disgust\": 0 or 1,\n","      \"Fear\": 0 or 1,\n","      \"Surprise\": 0 or 1,\n","      \"Anger\": 0 or 1,\n","      \"Other\": 0 or 1,\n","      \"Neutral\": 0 or 1\n","    }}\n","\n","    IMPORTANT:\n","    - Use ONLY 0 or 1 as values (0 = not present, 1 = present)\n","    - Do NOT add ANY comments, explanations, or text outside the JSON\n","    - Do NOT use // or /* */ comment syntax anywhere in your response\n","    - ONLY return a valid JSON object with no additional text or characters\n","    - Multiple emotions can be present simultaneously (have value 1)\n","\n","    Consider the voice tone, intonation, pace of the audio, as well as the text content.\n","    \"\"\"\n","\n","    try:\n","        response = model.generate_content([\n","            prompt,\n","            {\"mime_type\": \"audio/wav\", \"data\": audio_data}\n","        ])\n","\n","        emotion_text = response.text.strip()\n","\n","        json_match = re.search(r'({.*})', emotion_text, re.DOTALL)\n","        if json_match:\n","            emotion_text = json_match.group(1)\n","\n","        cleaned_json = clean_json_string(emotion_text)\n","\n","        try:\n","            emotion_dict = json.loads(cleaned_json)\n","            ordered_dict = {emotion: emotion_dict.get(emotion, 0) for emotion in EMOTIONS}\n","            return ordered_dict\n","        except json.JSONDecodeError:\n","            print(f\"JSON 파싱 오류: {emotion_text}\")\n","\n","            try:\n","                manual_dict = {}\n","                for emotion in EMOTIONS:\n","                    pattern = rf'\"?{emotion}\"?\\s*:\\s*(\\d+)'\n","                    match = re.search(pattern, emotion_text)\n","                    if match:\n","                        manual_dict[emotion] = int(match.group(1))\n","                    else:\n","                        manual_dict[emotion] = 0\n","\n","                if any(manual_dict.values()):\n","                    print(\"수동 추출 성공!\")\n","                    return manual_dict\n","            except Exception:\n","                pass\n","\n","            return {\"Error\": \"JSON 파싱 오류\"}\n","\n","    except Exception as e:\n","        print(f\"분석 중 오류 발생: {e}\")\n","        return {\"Error\": str(e)}\n","\n","for emotion in EMOTIONS:\n","    df[emotion] = 0\n","\n","df['primary_emotion'] = None\n","\n","for idx, row in df.iterrows():\n","    filename = row['filename']\n","    text = row['text']\n","\n","    print(f\"Processing {idx+1}/{len(df)}: {filename}\")\n","    print(f\"Text: '{text}'\")\n","\n","    audio_path = os.path.join(audio_dir, filename)\n","\n","    if os.path.exists(audio_path):\n","        try:\n","            audio_data = get_audio_data(audio_path)\n","\n","            emotion_results = analyze_audio_and_text(audio_data, text)\n","\n","            if 'Error' in emotion_results:\n","                print(f\"Error: {emotion_results['Error']}\")\n","                continue\n","\n","            for emotion, is_present in emotion_results.items():\n","                df.at[idx, emotion] = is_present\n","\n","            detected_emotions = [emotion for emotion, is_present in emotion_results.items() if is_present == 1]\n","\n","            if detected_emotions:\n","                df.at[idx, 'primary_emotion'] = detected_emotions[0]\n","            else:\n","                df.at[idx, 'primary_emotion'] = 'None'\n","\n","            print(\"감정 분석 결과:\")\n","            for emotion in EMOTIONS:\n","                present = emotion_results.get(emotion, 0)\n","                status = \"있음\" if present == 1 else \"없음\"\n","                print(f\"  {emotion}: {status}\")\n","\n","            print(f\"검출된 감정들: {', '.join(detected_emotions) if detected_emotions else '없음'}\")\n","            print(f\"주 감정: {df.at[idx, 'primary_emotion']}\")\n","\n","            if (idx + 1) % 10 == 0:\n","                df.to_csv(f'vocals_with_emotions_partial_{idx+1}.csv', index=False)\n","\n","        except Exception as e:\n","            print(f\"오디오 처리 중 오류 발생: {e}\")\n","    else:\n","        print(f\"오디오 파일을 찾을 수 없음: {audio_path}\")\n","\n","    print(\"-\" * 50)\n","    time.sleep(1)\n","\n","df.to_csv('vocals_with_emotions.csv', index=False)"],"metadata":{"id":"tyqYiFLahtXc"},"execution_count":null,"outputs":[]}]}